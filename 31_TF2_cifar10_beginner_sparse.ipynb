{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "31_TF2_cifar10_beginner_sparse.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmcPzSWs-LTI"
      },
      "source": [
        "# CIFAR10\n",
        "\n",
        "아래의 code는 google colab 에서 시험된 결과이다.\n",
        "Anaconda 에서 제공되는 jupyter notebook에서는 작동이 안될수 있다.\n",
        "추천하는 방법은 notebook이 아니라 python 파일 자체를 실행하라는 것이다. TPU 예제만 빼고는 anaconda prompt 에서 *.py 파일을 실행하는 방법을 추천한다.\n",
        "compare 도구로서는 \"BCcompare\"를 추천한다. working day로 30일간 무료로 사용이 가능하다.\n",
        "무료 사용후 재 설치 하면 다시 30 working day동안 사용이 가능하다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMPrRugTzwzZ"
      },
      "source": [
        "Compare 도구를 사용하여, \"01_TF2_MNIST_beginner_sparse.py\"와 \"31_TF2_cifar10_beginner_sparse.py\"를 비교하여 차이가 나는 부분을 살펴보자.\n",
        "차이가 나는 부분은 image의 size와 channel정도이다.\n",
        "CIFAR10은 image의 크기가 32이고 color로 되어 있기 때문이다.\n",
        "CIFAR10 또한 tensorflow 및 Keras에서 이미 dataset 형태로 제공된다.\n",
        "데이터의 변환은 추후에 별도의 저장소에서 강으하도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "VxwNCuyi0bPh",
        "outputId": "e49bc6d2-11e2-49d6-a823-e9b87e85c580"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "IMG_SIZE = 32\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "\n",
        "print(X_train.shape[0])\n",
        "print(X_test.shape[0])\n",
        "# sys.exit()\n",
        "\n",
        "# cv2.resize(X_train[i], (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "print(Y_train[0:10])\n",
        "\n",
        "# in the case of Keras or TF2, type shall be [image_size, image_size, 1]\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, epochs=5, verbose=1)\n",
        "\n",
        "model.evaluate(X_test,  Y_test, verbose=2)              \n",
        "\n",
        "\"\"\"\n",
        "verbose default is 1\n",
        "\n",
        "verbose=0 (silent)\n",
        "\n",
        "verbose=1 (progress bar)\n",
        "\n",
        "Train on 186219 samples, validate on 20691 samples\n",
        "Epoch 1/2\n",
        "186219/186219 [==============================] - 85s 455us/step - loss: 0.5815 - acc: \n",
        "0.7728 - val_loss: 0.4917 - val_acc: 0.8029\n",
        "Train on 186219 samples, validate on 20691 samples\n",
        "Epoch 2/2\n",
        "186219/186219 [==============================] - 84s 451us/step - loss: 0.4921 - acc: \n",
        "0.8071 - val_loss: 0.4617 - val_acc: 0.8168\n",
        "\n",
        "\n",
        "verbose=2 (one line per epoch)\n",
        "\n",
        "Train on 186219 samples, validate on 20691 samples\n",
        "Epoch 1/1\n",
        " - 88s - loss: 0.5746 - acc: 0.7753 - val_loss: 0.4816 - val_acc: 0.8075\n",
        "Train on 186219 samples, validate on 20691 samples\n",
        "Epoch 1/1\n",
        " - 88s - loss: 0.4880 - acc: 0.8076 - val_loss: 0.5199 - val_acc: 0.8046\n",
        " \n",
        " \"\"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "50000\n",
            "10000\n",
            "[[6]\n",
            " [9]\n",
            " [9]\n",
            " [4]\n",
            " [1]\n",
            " [1]\n",
            " [2]\n",
            " [7]\n",
            " [8]\n",
            " [3]]\n",
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9946 - accuracy: 0.2658\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 1.8917 - accuracy: 0.3045\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 1.8640 - accuracy: 0.3168\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 1.8502 - accuracy: 0.3211\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 1.8398 - accuracy: 0.3236\n",
            "313/313 - 1s - loss: 1.7463 - accuracy: 0.3715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nverbose default is 1\\n\\nverbose=0 (silent)\\n\\nverbose=1 (progress bar)\\n\\nTrain on 186219 samples, validate on 20691 samples\\nEpoch 1/2\\n186219/186219 [==============================] - 85s 455us/step - loss: 0.5815 - acc: \\n0.7728 - val_loss: 0.4917 - val_acc: 0.8029\\nTrain on 186219 samples, validate on 20691 samples\\nEpoch 2/2\\n186219/186219 [==============================] - 84s 451us/step - loss: 0.4921 - acc: \\n0.8071 - val_loss: 0.4617 - val_acc: 0.8168\\n\\n\\nverbose=2 (one line per epoch)\\n\\nTrain on 186219 samples, validate on 20691 samples\\nEpoch 1/1\\n - 88s - loss: 0.5746 - acc: 0.7753 - val_loss: 0.4816 - val_acc: 0.8075\\nTrain on 186219 samples, validate on 20691 samples\\nEpoch 1/1\\n - 88s - loss: 0.4880 - acc: 0.8076 - val_loss: 0.5199 - val_acc: 0.8046\\n \\n '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    }
  ]
}