{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "23_TF2_MNIST_expert_subclass.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmcPzSWs-LTI"
      },
      "source": [
        "# MNIST\n",
        "\n",
        "아래의 code는 google colab 에서 시험된 결과이다.\n",
        "Anaconda 에서 제공되는 jupyter notebook에서는 작동이 안될수 있다.\n",
        "추천하는 방법은 notebook이 아니라 python 파일 자체를 실행하라는 것이다. TPU 예제만 빼고는 anaconda prompt 에서 *.py 파일을 실행하는 방법을 추천한다.\n",
        "compare 도구로서는 \"BCcompare\"를 추천한다. working day로 30일간 무료로 사용이 가능하다.\n",
        "무료 사용후 재 설치 하면 다시 30 working day동안 사용이 가능하다.\n",
        "\n",
        "Compare 도구를 사용하여, \"21_TF2_MNIST_expert_sequential_sparse.py\"와 \"23_TF2_MNIST_expert_subclass.py\"를 비교하여 차이가 나는 부분을 살펴보자."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD6y3eOKaI-7"
      },
      "source": [
        "아래의 code 부분만 변경된것을 볼수 있다.\n",
        "\n",
        "```\n",
        "class MyModel(Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv1 = Conv2D(64, 3, activation='relu', padding='SAME')\n",
        "        self.maxpool2d1 = MaxPool2D(padding='SAME')\n",
        "        self.conv2 = Conv2D(filters=128, kernel_size=3, activation=tf.nn.relu, padding='SAME')\n",
        "        self.maxpool2d2 = MaxPool2D(padding='SAME')\n",
        "        self.conv3 = Conv2D(filters=256, kernel_size=3, activation=tf.nn.relu, padding='SAME')\n",
        "        self.maxpool2d3 = MaxPool2D(padding='SAME')\n",
        "        self.flatten = Flatten()\n",
        "        self.d1 = Dense(256, activation='relu')\n",
        "        self.d2 = Dropout(0.2)\n",
        "        self.d3 = Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool2d1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpool2d2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.maxpool2d3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.d1(x)\n",
        "        x = self.d2(x)\n",
        "        return self.d3(x)\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "```\n",
        "Colab에서 제공하는 전문가를 위한 빠른 시작 부분에서는 갑자기 code가 바뀌었다. Colab 에서 제공하는 \"초보자를 위한 빠른시작\"과 \"전문가를 위한 빠른 시작\"의 큰 차이점은 두개임을 기억하자.\n",
        "\"tf.data.Dataset.\"와 \"tf.GradientTape()\"이 두가지가 큰 차이가 있다.\n",
        "\n",
        "위의 network 정의하는 방법은 세가지 방법중 한가지 임을 기억하자."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKHBMPyxnfJp"
      },
      "source": [
        "아래부분은 \"21_TF2_MNIST_expert_sequential_sparse.py\"와 \"23_TF2_MNIST_expert_subclass.py\" 가 동일한 부분이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCb0YcACnnVy",
        "outputId": "1baa687c-4629-4ae0-d18b-57a819a7ee66"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
        "from tensorflow.keras import Model, Sequential\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "# print(tf.__version__)\n",
        "## MNIST Dataset #########################################################\n",
        "mnist = tf.keras.datasets.mnist\n",
        "# class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "##########################################################################\n",
        "\n",
        "## Fashion MNIST Dataset #################################################\n",
        "# mnist = tf.keras.datasets.fashion_mnist\n",
        "# class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "##########################################################################\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()    \n",
        "\n",
        "# Change data type as float. If it is unt type, it might cause error \n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "print(Y_train[0:10])\n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "# in the case of Keras or TF2, type shall be [image_size, image_size, 1]\n",
        "# if it is RGB type, type shall be [image_size, image_size, 3]\n",
        "# For MNIST or Fashion MNIST, it need to reshape\n",
        "X_train = X_train[..., tf.newaxis]\n",
        "X_test = X_test[..., tf.newaxis]\n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "batch_size = 1000\n",
        "# 입력된 buffer_size만큼 data를 채우고 무작위로 sampling하여 새로운 data로 바꿉니다.\n",
        "# 완벽한 셔플링을 위해서는 데이터 세트의 전체 크기보다 크거나 같은 버퍼 크기가 필요합니다.\n",
        "# 만약 작은 데이터수보다 작은 buffer_size를 사용할경우,\n",
        "# 처음에 설정된 buffer_size만큼의 data안에서 임의의 셔플링이 발생합니다.\n",
        "shuffle_size = 100000\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (X_train, Y_train)).shuffle(shuffle_size).batch(batch_size)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(batch_size)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "[5 0 4 1 9 2 1 3 1 4]\n",
            "(60000, 28, 28)\n",
            "(60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWL3N6wgnnxm"
      },
      "source": [
        "아래부분은 \"21_TF2_MNIST_expert_sequential_sparse.py\"와 \"23_TF2_MNIST_expert_subclass.py\" 는 network의 정의만 다르다.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mOPQB1CnuMr"
      },
      "source": [
        "\n",
        "class MyModel(Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv1 = Conv2D(64, 3, activation='relu', padding='SAME')\n",
        "        self.maxpool2d1 = MaxPool2D(padding='SAME')\n",
        "        self.conv2 = Conv2D(filters=128, kernel_size=3, activation=tf.nn.relu, padding='SAME')\n",
        "        self.maxpool2d2 = MaxPool2D(padding='SAME')\n",
        "        self.conv3 = Conv2D(filters=256, kernel_size=3, activation=tf.nn.relu, padding='SAME')\n",
        "        self.maxpool2d3 = MaxPool2D(padding='SAME')\n",
        "        self.flatten = Flatten()\n",
        "        self.d1 = Dense(256, activation='relu')\n",
        "        self.d2 = Dropout(0.2)\n",
        "        self.d3 = Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool2d1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpool2d2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.maxpool2d3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.d1(x)\n",
        "        x = self.d2(x)\n",
        "        return self.d3(x)\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "# model.summary()\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kddsVvcnu6F"
      },
      "source": [
        "아래부분은 \"21_TF2_MNIST_expert_sequential_sparse.py\"와 \"23_TF2_MNIST_expert_subclass.py\" 가 동일한 부분이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHL5rrBOnwXn",
        "outputId": "227358f9-2cb6-486c-fa27-2dedd2c1fafe"
      },
      "source": [
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images)\n",
        "        loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "    predictions = model(images)\n",
        "    t_loss = loss_object(labels, predictions)\n",
        "\n",
        "    test_loss(t_loss)\n",
        "    test_accuracy(labels, predictions)\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for images, labels in train_ds:\n",
        "        train_step(images, labels)\n",
        "\n",
        "    for test_images, test_labels in test_ds:\n",
        "        test_step(test_images, test_labels)\n",
        "\n",
        "    template = 'epoch: {:>5,d}, loss: {:>2.4f}, accuracy: {:>2.3f}%, test loss: {:>2.4f}, test accuracy: {:>2.3f}%'\n",
        "    print (template.format(epoch+1,\n",
        "                         train_loss.result(),\n",
        "                         train_accuracy.result()*100,\n",
        "                         test_loss.result(),\n",
        "                         test_accuracy.result()*100))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "epoch:     1, loss: 0.5038, accuracy: 84.645%, test loss: 0.0959, test accuracy: 96.890%\n",
            "epoch:     2, loss: 0.2897, accuracy: 91.166%, test loss: 0.0701, test accuracy: 97.690%\n",
            "epoch:     3, loss: 0.2087, accuracy: 93.631%, test loss: 0.0572, test accuracy: 98.090%\n",
            "epoch:     4, loss: 0.1654, accuracy: 94.951%, test loss: 0.0504, test accuracy: 98.298%\n",
            "epoch:     5, loss: 0.1378, accuracy: 95.795%, test loss: 0.0457, test accuracy: 98.462%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}