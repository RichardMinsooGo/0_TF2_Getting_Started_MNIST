{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF2.X 버전을 사용하는 이유는\n",
    "\n",
    "1. 초보자들에게 High Level API를 제공\n",
    "2. Keras 에서 제공하는 Transfer Learning 을 사용할수 있다.\n",
    "Tensorflow 1.X 에서는 이를 구현하기가 어려움\n",
    "3. TPU 사용 가능\n",
    "4. Notebook 사용의 한계\n",
    "5. TF2.X 및 Keras의 한계\n",
    "6. Google Colab의 주의사항"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 초보자들이 TF1.X를 사용하혀면 graph 의 구조에 대한 이해가 필요하나 TF2.X는 그러한 지식이 없이도 간단한 문제들은 구현이 가능함.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. TF 1.X 사용 자들이 많이 만나는 이슈중에 하나가 이전에 학습된 weights 들을 다루기가 어려운 부분들이 있다.\n",
    "Keras 에서는 이를 다루기가 쉽게 되어 있다.\n",
    "TF2.X에서는 Keras 에서 지원하는 모든 기능을 지원하지는 않는다. \n",
    "몇가지 기능이 빠져있다.\n",
    "Transfer Learning 의 고급 기능 coding에 대해서는 강화학습 고급 과정에서 다룬다.\n",
    "Transfer Learning 을 사용하기 싫은 사람들은 Cifar100 정도를 처음부터 학습해보면 된다.이에 대한 code도 이미 완성되었으므로 제공할 예정이다. TPU 시험 용도로 개발한 code를 제공항 예정이니 사용해보면 transfer learning의 이유를 알수 있다.\n",
    "심심한신 연구자들은 imagenet을 처음부터 학습시켜보면 된다. 일반적인 GPU 가지고 몇년이내에 가능할지 모르겠지만...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. TPU 사용\n",
    "Google Colab에서 지원하는 강력한 기능이 TPU 이다.\n",
    "향후 이에대해서는 상세하게 coding 을 진행한다.\n",
    "수많은 source code를 제공할 예정이다.\n",
    "Google 에서 제공하는 example들은 몇가지 특별한 경우에 대해서만 제공되어져 있고, 실제 개발자들이 필요할만한 내용들은 빠져 있다.\n",
    "Colab 에서 제공하는 무료 TPU의 단점은 크게 두가지 인데, 한가지는 접속하기가 힘들다. \n",
    "하지만 무료니깐 참자. 예산이 충분하면 딥러닝용 전용 컴퓨터를 장만하는것을 권장한다. Colab은 가난한 연구자를 위해서는 추천할만하나, 보안이나 작업 효울성을 위해서는 추천하지 않는다.\n",
    "두번째 단점은, with strategy.scope(): 지정이 상당히 어렵다는 것이다. \n",
    "기존의 GPU 모드에서는 작동이 잘 되다가도, TPU 모드로 변환하면 안되는 code들이 존재한다.\n",
    "Code analysis 를 해보면 이상이 발생 안해야 하는데, 발생하는 경우들이 많다.\n",
    "따라서 상업용 개발자들은 강력한 GPU 여러개를 사용하는것을 권장한다.\n",
    "\n",
    "사용하는 이유는 단순하다.\n",
    "Cifar100 정도의 문제를 해결해 보면, TPU 기능을 왜 사용하는지 알수 있다.\n",
    "Cifar10이나, MNIST, Fashion MNIST 나 기타 샘플로 주어지는 문제들은 연습 정도로 보면 된다.\n",
    "하지만 Cifar100정도 부터는 게임의 수준이 다르다.\n",
    "시간 많으신 연구자들은 Cifar100를 일반 RAM 모드에서 시험해보기를 빈다.\n",
    "\n",
    "TPU는 범용 장비가 아님을 기억하자. 똑같은 coding을 가지고도 작동이 될때가 있고 안될때가 있다. Google에서 어떤 제약조건을 걸어 놓은것 같기는 헌데, 사용자로서는 알 길이 없다.\n",
    "그리니 TPU를 가지고 모든 학습을 진행하는것은 그다지 추천하지 않는다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Notebook 사용의 한계\n",
    "Notebook(=ipynb 확장자를 사용하는 파일들)은 compare tool을 쓰기것이 거의 불가능하다.\n",
    "따라서 posting에 사용되는 모든 Notebook파일들은 별도의 python 파일을 마들어 놓을 예정이다.\n",
    "필자가 TF1.X Github repository 에서는 python파일만 가지고 구성해 놓았다.\n",
    "이는 고급 사용자들에게는 쉽지만, 초보자들에게는 너무 큰 장벽일수도 이다.\n",
    "이유는 python 파일 자체를 가지고서는 주석을 달기가 상당히 힘들다. \n",
    "그리고 설명을 하려면 파일들이 보기가 어려워 진다.\n",
    "어느정도의 고급 사용자가 되면 Notebookㅇ리 필요가 없어질 것이나, 대부분의 연구자들은 어느정도 수준에 오를때까지는 Notebook과 Python 파일을 같이 사용하는 습관을 가지면 된다.\n",
    "이렇게 사용되는 Notebook은 고급 프로그래밍을 하기엔느 상당히 어렵게 되어 있다는것을 알면 된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5. TF2.X 및 Keras의 한계\n",
    "Keras도 상당히 잘만들어졌고, TF2.X에서 이를 통합하여 운영하는것은 상당히 훌륭한 결정이었던것 같다.\n",
    "그리고 TF2.X에 대한 Posting들을 보면 강점만 열거해 놔서 단점이 없어 보인다.\n",
    "하지만 모든것을은 밝은 면이 있으면 어두운 면이 있기 마련이다.\n",
    "Keras를 가지고 구현이 정말 어려운 부분이 있는데, 아무래도 Google에서 TF2.X 개발 중에 놓친부분인지 모르겠다.\n",
    "Keras 를 가지고 A3C를 구현하면 정확하게 구현이 안되는 부분이 한군데가 나온다.\n",
    "TF1.X가지고는 명확히 구현이 되지만, 이를 TF2.X에서는 안될지도 모르겠다. \n",
    "이부분은 시간이 많이 남으면 좀 더 deep하게 연구 후에 posting을 하도록 하겠습니다.\n",
    "연구자들이 명확히 알아두어야 할 부분은 Keras와 TF2.X가 TF1.X에 비해서 구현이 안되는 부분ㅇ도 존재한다는것을 명심하시면 됩니다.\n",
    "그리고 trasfer learning 부분에서는 Keras가 TF2.X 보다 좀더 강력하는것을 명심해두면 됩니다.\n",
    "개인적인 견해로서는 TF2.X에서 아직 이부분 coding이 좀 덜된듯 합니다.\n",
    "\n",
    "분명한점은 TF2.X나 Keras 의 도움으로 deep learning 연구에 지대한 공헌을 하고 있다는 점을 명심하자.\n",
    "필자가 deep learning을 시작할때만 하더라도, 8Mbyte의 RAM과 팬티엄프로세서를 사용하던 시절이었다.\n",
    "이정도만 하더라도, 연구소에서나 볼수있는 정도의 컴퓨터 사양이었다.\n",
    "그 시절만 하더라도 일반인들은 4Mbyte 메모리와 80486 초기 프로세서를 사용하던 시절이었었고, 신경망과 관련된 알고리즘을 직접 만들어 쓰던 시절이었다.\n",
    "그때에 비하면 2020년 현재는 너무나도 많은 발전을 이뤄냈으니, TF나 Keras가 조금 부족한 부분이 있더라고 고쳐서 쓰려는 마인드가 필요하다.\n",
    "불평하려는 연구자들은, 돈벌어서 google을 인수해서 고치도록 명령하면 될것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Google Colab의 주의사항\n",
    "Colab 노트북에서 사용되는 code 들을 사용할대는 tab 사용에 주의하기 바란다.\n",
    "Google에서 왜 그렇게 colab tab을 지정해 놨는지는 모르겠으나, 필자의 견해로는 일부러 그렇게 만들어 놨을수도 있다. \n",
    "다른 노트북은 tab 의 길이가 8칸이다.\n",
    "다른 노트북에서 만들어진 code들은 Colab 에서 잘 돌아 간다.\n",
    "하지만 colab에서 만들어진 Notebook을 다른곳에서 구현하려면 이를 전부 수정해주어야 한다.\n",
    "그리고 colab 환경에서 작동하느 code들과 Anaconda 환경에서 작동하는 code들은 얀간의 차이가 있다.\n",
    "단순한 계산을 하는 연구자들은 그차이를 느낄수 없을지 모르나, 고급 사용자들은 그러한 부분이 있다는것을 명심해두자.\n",
    "역시 이부분도 시간이 되면 좀더 깊게 posting을 진행하면 좋겠으나, 아주 중요한부분은 아니라서 시간이 나면 posting 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Conclusion\n",
    "많은 중역분들이나 연구자들이 miss 하는 부분이 있는데, 모든것을 만족시키는 tool은 없다는것을 까먹는다.\n",
    "내가 운영하는 github repository에 들어왔을 정도면, 이미 최신 기술에 어느정도 접근해 있는 분들입니다.\n",
    "즉 그말은 이글을 읽는 사람들은 완벽하지 않는 tool들을 다뤄야 하고, 그것을 가지고 좀더 발전된 것을 만들어야 하는 숙명을 가진 사람들이라는것이다.\n",
    "지금까지 수많은 프로젝트에서 integration과 system arhitecture 를 담당하면서 문제가 없었던 적은 한번도 없었다.\n",
    "이러한 수많은 도전을 해결하면서 바뀌지 않는 rule이 있다.\n",
    "도전 정신을 가지고, 전문가들과 communication을 하면서, 직면한 과제를 해결하기 위해서 최선을다해서 토론하고 논의해서 수많은 trial 을 하면 대부분의 경우는 문제는 풀리게 되어 있다.\n",
    "\n",
    "이제 TF2.X에서 펼쳐지는 새로운 세계를 만나러가자."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
