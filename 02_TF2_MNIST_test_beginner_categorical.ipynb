{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "02_TF2_MNIST_test_beginner_categorical.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmcPzSWs-LTI"
      },
      "source": [
        "# MNIST\n",
        "\n",
        "아래의 code는 google colab 에서 시험된 결과이다.\n",
        "Anaconda 에서 제공되는 jupyter notebook에서는 작동이 안될수 있다.\n",
        "추천하는 방법은 notebook이 아니라 python 파일 자체를 실행하라는 것이다. TPU 예제만 빼고는 anaconda prompt 에서 *.py 파일을 실행하는 방법을 추천한다.\n",
        "compare 도구로서는 \"BCcompare\"를 추천한다. working day로 30일간 무료로 사용이 가능하다.\n",
        "무료 사용후 재 설치 하면 다시 30 working day동안 사용이 가능하다.\n",
        "\n",
        "```\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "```\n",
        "는 Y_train/Y_test 의 형식을 one-hot의 형태로 변경하기 위해서 추가 되어진다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaIJGVc_DXLy"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4akrtewENiq"
      },
      "source": [
        "아래의 코드를 보면\n",
        "```\n",
        "Y_train = to_categorical(Y_train, 10)\n",
        "Y_test = to_categorical(Y_test, 10)   \n",
        "```\n",
        "가 추가 되어져 있다.\n",
        "\n",
        "이는 categorical_crossentropy를 loss 함수로 사용하기 위해서 one-hot으로 변경 해주는 부분이다.\n",
        "\n",
        "Y_train을 10개를 출력해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4FxFYqyFE8P",
        "outputId": "58454947-d831-41e7-80f6-49f52ad14b8f"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "print(Y_train[0:10])\n",
        "\n",
        "Y_train = to_categorical(Y_train, 10)\n",
        "Y_test = to_categorical(Y_test, 10)    \n",
        "\n",
        "print(Y_train[0:10].astype(int))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 0 4 1 9 2 1 3 1 4]\n",
            "[[0 0 0 0 0 1 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXo4s4OMGIZ9"
      },
      "source": [
        "출력된 결과는 0~9까지의 숫자로 표현될때와 one-hot으로 표현되어질때를 비교하여 출력한것이다.\n",
        "\n",
        "```\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "\"01_tf2_mnist_test_beginner_sparse.py\"와 비교하면 loss 함수가 변경된것을 볼수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "R9pn3fEtH0BO",
        "outputId": "a9791563-ba10-42a6-89a0-08c68a0c8b29"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, epochs=5, verbose=1)\n",
        "\n",
        "model.evaluate(X_test,  Y_test, verbose=2)              \n",
        "\n",
        "\"\"\"\n",
        "verbose default is 1\n",
        "\n",
        "verbose=0 (silent)\n",
        "\n",
        "verbose=1 (progress bar)\n",
        "\n",
        "Train on 186219 samples, validate on 20691 samples\n",
        "Epoch 1/2\n",
        "186219/186219 [==============================] - 85s 455us/step - loss: 0.5815 - acc: \n",
        "0.7728 - val_loss: 0.4917 - val_acc: 0.8029\n",
        "Train on 186219 samples, validate on 20691 samples\n",
        "Epoch 2/2\n",
        "186219/186219 [==============================] - 84s 451us/step - loss: 0.4921 - acc: \n",
        "0.8071 - val_loss: 0.4617 - val_acc: 0.8168\n",
        "\n",
        "\n",
        "verbose=2 (one line per epoch)\n",
        "\n",
        "Train on 186219 samples, validate on 20691 samples\n",
        "Epoch 1/1\n",
        " - 88s - loss: 0.5746 - acc: 0.7753 - val_loss: 0.4816 - val_acc: 0.8075\n",
        "Train on 186219 samples, validate on 20691 samples\n",
        "Epoch 1/1\n",
        " - 88s - loss: 0.4880 - acc: 0.8076 - val_loss: 0.5199 - val_acc: 0.8046\n",
        " \n",
        " \"\"\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2935 - accuracy: 0.9145\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1418 - accuracy: 0.9585\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1049 - accuracy: 0.9678\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0870 - accuracy: 0.9736\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0746 - accuracy: 0.9763\n",
            "313/313 - 0s - loss: 0.0708 - accuracy: 0.9781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nverbose default is 1\\n\\nverbose=0 (silent)\\n\\nverbose=1 (progress bar)\\n\\nTrain on 186219 samples, validate on 20691 samples\\nEpoch 1/2\\n186219/186219 [==============================] - 85s 455us/step - loss: 0.5815 - acc: \\n0.7728 - val_loss: 0.4917 - val_acc: 0.8029\\nTrain on 186219 samples, validate on 20691 samples\\nEpoch 2/2\\n186219/186219 [==============================] - 84s 451us/step - loss: 0.4921 - acc: \\n0.8071 - val_loss: 0.4617 - val_acc: 0.8168\\n\\n\\nverbose=2 (one line per epoch)\\n\\nTrain on 186219 samples, validate on 20691 samples\\nEpoch 1/1\\n - 88s - loss: 0.5746 - acc: 0.7753 - val_loss: 0.4816 - val_acc: 0.8075\\nTrain on 186219 samples, validate on 20691 samples\\nEpoch 1/1\\n - 88s - loss: 0.4880 - acc: 0.8076 - val_loss: 0.5199 - val_acc: 0.8046\\n \\n '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}